---

- name: Enable Lustre server repos
  tags: yum, kernel, repos, update
  yum_repository:
    name: "{{ item.name }}"
    description: "{{ item.name }}"
    baseurl: "{{ item.url }}"
    gpgkey: "{{ item.gpgkey | default(omit) }}"
    gpgcheck: "{{ item.gpgcheck | default(omit) }}"
    enabled: "{{ item.enabled | default(omit) }}"
    exclude: "{{ item.exclude | default(omit) }}"
    state: "{{ item.state | default(omit) }}"
  with_items: "{{ lustre_repos | default({}) }}"

- name: Install Lustre kernel package
  tags: yum, kernel, update
  yum:
    name: "{{ lustre_kernel_pkg }}"
    state: installed
  when: inventory_hostname in groups.lustre_servers and only_kernel|default(false)

- name: Check for reboot hint.
  tags: kernel, update
  shell: needs-restarting -r
  register: needs_restart
  failed_when: needs_restart.rc > 1

- name: Reboot the server for kernel update
  tags: kernel, update
  reboot:
    msg: "Rebooting to new lustre kernel"
  when:
     - needs_restart.rc == 1
     - only_kernel|default(false)

- name: Install Lustre server phase 1 Whamcloud-packages
  tags: kernel, ph1, update
  yum: 
    name: "{{ lustre_ph1_packages }}"
    state: installed
  when: only_kernel|default(false)
  #  disablerepo: Mellanox-IB

- name: Install Lustre-server Mellanox-packages
  tags: ph1, update
  yum:
    name: "{{ mellanox_packages }}"
    enablerepo: "{{ mlnx_ofed_repo }}"
    state: installed
  when: not only_kernel

- name: Restart openibd
  tags: ph1, update
  service: 
    name: openibd
    state: restarted
  when: only_kernel|default(false)

- name: Install Lustre server packages
  tags: yum, update
  yum:
    name: "{{ lustre_server_packages }}"
    state: latest
  when: not only_kernel

- name: Lustre modprobe.d configs
  tags: lnet, update
  template: src=lustre.conf.j2 dest=/etc/modprobe.d/lustre.conf
            owner=root group=root mode=0644
  when: not only_kernel

- name: Lustre lnet config
  tags: lnet, update
  template: src=lnet.conf.j2 dest=/etc/lnet.conf
            owner=root group=root mode=0644
  when: not only_kernel

- name: Enable lnet systemd service
  tags: lnet, update
  systemd:
    name: lnet
    state: started
    enabled: True
  when: not only_kernel

- name: Check Lustre networks
  tags: lnet, update
  command: /usr/sbin/ip link show {{ item }}
  with_items: "{{ lustre_network_devices|default([]) }}"
  register: lustre_networks
  failed_when: False
  changed_when: lustre_networks.rc != 0
  when: not only_kernel

- name: Bring up Lustre networks if down
  tags: lnet, update
  command: /usr/sbin/ifup {{ item[1] }}
 # when: item[0].rc != 0 and not only_kernel
  when: not only_kernel
  with_nested:
    - "{{ lustre_networks.results }}"
    - "{{ lustre_network_devices|default([]) }}"
    #  when: ansible_connection != 'chroot'

- name: Load Lustre modules
  tags: lnet, update
  modprobe: name=lustre
  when: ansible_connection != 'chroot' and not only_kernel

- name: Let's create Lustre OST directories
  file:
    path: "{{ item.dir }}"
    state: "directory"
  tags: ost
  loop: "{{ osts[inventory_hostname] }}"
  when: not only_kernel and osts[inventory_hostname] is defined

- name: Lets make sure journal-volumes exists
  tags: ost, mkfs, journal
  lvol: 
    lv: "{{ item.journal | default('No') }}"
    vg: "vgroot"
    state: present
    size: 4G
  loop: "{{ osts[inventory_hostname] }}"
  when: not only_kernel and osts[inventory_hostname] is defined

- name: Let's bruteforce all necessary FSs
  tags: ost, mkfs
  script: "mk_lustre_ost.sh {{ item.dev }} {{ item.index }} {{ item.journal | default('No') }}"
  register: myscript
  changed_when: myscript.rc == 2
  failed_when: myscript.rc != 0 and myscript.rc != 2
  loop: "{{ osts[inventory_hostname] }}"
  when: not only_kernel and osts[inventory_hostname] is defined

- name: Add OSTS to /etc/fstab
  tags: ost, fstab, mount
  mount: 
    backup: yes
    boot: yes
    fstype: lustre
    path: "{{item.dir}}"
    src: "UUID={{ ansible_facts['devices'][item.dev | regex_replace('/dev/') ]['links']['uuids'][0] }}"
    state: mounted
  loop: "{{ osts[inventory_hostname] }}"
  when: not only_kernel and osts[inventory_hostname] is defined 

- name: Add OST to named disk_pool
  tags: ost, mount, pool
  script: "lustre-diskpool.sh {{ item.pool }} OST00{{ item.index | regex_replace('0x') }} "
  loop: "{{ osts[inventory_hostname] }}"
  delegate_to: "{{ lustre_mgs }}"
  when: not only_kernel and osts[inventory_hostname] is defined

- name: Create new keypair for Lustre IM
  tags: lim
  openssh_keypair: path="/root/.ssh/lustre-im" type=ed25519 state=present
  when: "lim_manager| default (False) and only_kernel|default(false)"

- name: Instruct ssh to use the new key
  tags: lim
  lineinfile:
    dest=/root/.ssh/config 
    line='IdentityFile /root/.ssh/lustre-im'
    create=True
    state=present
    regexp='.*IdentityFile .*'
  when: "lim_manager| default (False) and only_kernel|default(false)"

- name: Let's fetch pub key for population.
  tags: lim
  fetch: src="/root/.ssh/lustre-im.pub" dest="files/lustre-im.pub" flat=yes
  when: "lim_manager| default (False) and only_kernel|default(false)"

- name: Lets populate lim-pubkey to nodes
  tags: lim
  authorized_key: key="{{ lookup('file', 'files/lustre-im.pub') }}" comment="Lustre Integrated Manager" state=present user=root
  when: "lim_manager| default (False) and only_kernel|default(false)"

#- name: check for existing journalfs
#  tags: ost, mkfs
#  script: is_lustrefs.sh /dev/mapper/vgroot-lv_ost{{ item.index }}
##  shell: |
##    /usr/bin/lsblk /dev/mapper/vgroot-lv_ost{{ item.index }} --fs -n
#  register: journals
#  loop: "{{ osts[inventory_hostname] }}"
  
#- name: Lets create journal filesystems
#  tags: ost, mkfs
#  filesystem: 
#    dev: /dev/mapper/vgroot-lv_ost{{ item.index }}
#    fstype: ext2
#    opts: "-b 4096 -O journal_dev -L OST_{{ item.index }}_jrnl"
#  loop: "{{ osts[inventory_hostname] }}"
##  when: ansible_device_links.labels == {} or not ansible_device_links.labels[item.dev[5:]][0] is search( 'OST_.*_jrnl' ) 
#
#- name: Lets create OST filesystems
#  shell: | 
#    {{ mkfs }} {{ fsname }} {{ mgs }} --ost --index={{ item.index }} {{ item.dev }}
#  tags: ost, mkfs
#  loop: "{{ osts[inventory_hostname] }}"
#  debugger: on_failed
#  when: ansible_device_links.labels == {} or not ansible_device_links.labels[item.dev[5:]][0] is search( '.*lustre:OST.*' ) 

# .labels contains array of labels for blockdevice
# so we only create new fs, when it doesn't already contain lustre-OST in label
 
#- name: Lustre modprobe.d confings
#  template: src=lustre.conf.j2 dest=/etc/modprobe.d/lustre.conf
#            owner=root group=root mode=0644
#
#- name: Lustre lnet config
#  template: src=lnet.conf.j2 dest=/etc/lnet.conf
#            owner=root group=root mode=0644
#
#- name: Enable lnet systemd service
#  systemd:
#    name: lnet
#    state: started
#    enabled: True
#
#- name: Check Lustre networks
#  command: /usr/sbin/ip link show {{ item }}
#  with_items: "{{ lustre_network_devices|default([]) }}"
#  register: lustre_networks
#  failed_when: False
#  changed_when: lustre_networks.rc != 0
#  when: ansible_connection != 'chroot'
#
